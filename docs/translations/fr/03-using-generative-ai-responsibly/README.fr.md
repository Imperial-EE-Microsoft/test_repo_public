# Utiliser l'IA g√©n√©rative de mani√®re responsable

[![Utiliser l'IA g√©n√©rative de mani√®re responsable](../../../translated_images/03-lesson-banner.6a8c4abb72a8ad1ae6d614bacb915198cb0e1cecbd6951c814d8ae903180ccbd.fr.png)]()

> **Vid√©o √† venir**

Il est facile d'√™tre fascin√© par l'IA, et l'IA g√©n√©rative en particulier, mais il est important de consid√©rer comment l'utiliser de mani√®re responsable. Il faut prendre en compte des √©l√©ments tels que l'assurance que la sortie est √©quitable, non nuisible, etc. Ce chapitre vise √† vous fournir le contexte n√©cessaire, ce qu'il faut prendre en compte et comment prendre des mesures actives pour am√©liorer votre utilisation de l'IA.

## Introduction

Cette le√ßon couvrira :

- Pourquoi vous devriez donner la priorit√© √† l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Les principes fondamentaux de l'IA responsable et comment ils se rapportent √† l'IA g√©n√©rative.
- Comment mettre en pratique ces principes d'IA responsable gr√¢ce √† des strat√©gies et des outils.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous saurez :

- L'importance de l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Quand penser et appliquer les principes fondamentaux de l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Quels outils et strat√©gies sont √† votre disposition pour mettre en pratique le concept d'IA responsable.

## Principes d'IA responsable

L'enthousiasme pour l'IA g√©n√©rative n'a jamais √©t√© aussi grand. Cet enthousiasme a attir√© de nombreux nouveaux d√©veloppeurs, de l'attention et des financements dans cet espace. Bien que cela soit tr√®s positif pour toute personne cherchant √† construire des produits et des entreprises en utilisant l'IA g√©n√©rative, il est √©galement important que nous proc√©dions de mani√®re responsable.

Tout au long de ce cours, nous nous concentrons sur la construction de notre startup et de notre produit d'√©ducation √† l'IA. Nous utiliserons les principes de l'IA responsable : l'√©quit√©, l'inclusion, la fiabilit√©/s√©curit√©, la s√©curit√© et la confidentialit√©, la transparence et la responsabilit√©. Avec ces principes, nous explorerons comment ils se rapportent √† notre utilisation de l'IA g√©n√©rative dans nos produits.

## Pourquoi devriez-vous donner la priorit√© √† l'IA responsable

Lorsque vous construisez un produit, adopter une approche centr√©e sur l'humain en gardant √† l'esprit les int√©r√™ts de vos utilisateurs conduit aux meilleurs r√©sultats.

La particularit√© de l'IA g√©n√©rative est sa capacit√© √† cr√©er des r√©ponses, des informations, des conseils et du contenu utiles pour les utilisateurs. Cela peut √™tre fait sans de nombreuses √©tapes manuelles, ce qui peut conduire √† des r√©sultats tr√®s impressionnants. Sans une planification et des strat√©gies appropri√©es, cela peut √©galement malheureusement conduire √† des r√©sultats nuisibles pour vos utilisateurs, votre produit et la soci√©t√© dans son ensemble.

Regardons quelques-uns (mais pas tous) de ces r√©sultats potentiellement nuisibles :

### Hallucinations

Les hallucinations sont un terme utilis√© pour d√©crire lorsque LLM produit un contenu qui est soit compl√®tement absurde, soit quelque chose que nous savons est factuellement incorrect en fonction d'autres sources d'information.

Prenons par exemple que nous construisons une fonctionnalit√© pour notre startup qui permet aux √©tudiants de poser des questions historiques √† un mod√®le. Un √©tudiant pose la question `Qui √©tait le seul survivant du Titanic ?`

Le mod√®le produit une r√©ponse comme celle ci-dessous :

![Prompt disant "Qui √©tait le seul survivant du Titanic"](../../../translated_images/ChatGPT-titanic-survivor-prompt.bae2f592150a472a5172d06e59b4742782710dc8933e3ca1f1b20f155887dbca.fr.webp)

> *(Source : [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))*

C'est une r√©ponse tr√®s confiante et approfondie. Malheureusement, elle est incorrecte. M√™me avec un minimum de recherche, on d√©couvrirait qu'il y avait plus d'un survivant du d√©sastre du Titanic. Pour un √©tudiant qui commence tout juste √† rechercher ce sujet, cette r√©ponse peut √™tre suffisamment persuasive pour ne pas √™tre remise en question et √™tre trait√©e comme un fait. Les cons√©quences de cela peuvent conduire √† ce que le syst√®me d'IA soit peu fiable et ait un impact n√©gatif sur la r√©putation de notre startup.

√Ä chaque it√©ration de tout LLM donn√©, nous avons vu des am√©liorations de performance autour de la minimisation des hallucinations. M√™me avec cette am√©lioration, nous en tant que constructeurs et utilisateurs d'applications devons toujours rester conscients de ces limites.

### Contenu nuisible

Nous avons vu dans la section pr√©c√©dente quand un LLM produit des r√©ponses incorrectes ou absurdes. Un autre risque dont nous devons √™tre conscients est lorsque le mod√®le r√©pond avec un contenu nuisible.

Le contenu nuisible peut √™tre d√©fini comme :

- Fournir des instructions ou encourager l'auto-mutilation ou la mutilation de certains groupes.
- Contenu haineux ou d√©gradant.
- Guider la planification de tout type d'attaque ou d'acte violent.
- Fournir des instructions sur la fa√ßon de trouver du contenu ill√©gal ou de commettre des actes ill√©gaux.
- Affichage de contenu sexuellement explicite.

Pour notre startup, nous voulons nous assurer que nous avons les bons outils et strat√©gies en place pour emp√™cher ce type de contenu d'√™tre vu par les √©tudiants.

### Manque d'√©quit√©

L'√©quit√© est d√©finie comme ¬´ s'assurer qu'un syst√®me d'IA est exempt de biais et de discrimination et qu'il traite tout le monde de mani√®re √©quitable et √©gale ¬ª. Dans le monde de l'IA g√©n√©rative, nous voulons nous assurer que les points de vue exclusifs des groupes marginalis√©s ne sont pas renforc√©s par la sortie du mod√®le.

Ces types de sorties ne sont pas seulement destructeurs pour la cr√©ation d'exp√©riences de produit positives pour nos utilisateurs, mais ils causent √©galement des pr√©judices suppl√©mentaires √† la soci√©t√©. En tant que constructeurs d'applications, nous devrions toujours garder √† l'esprit une base d'utilisateurs large et diversifi√©e lors de la cr√©ation de solutions avec l'IA g√©n√©rative.

## Comment utiliser l'IA g√©n√©rative de mani√®re responsable

Maintenant que nous avons identifi√© l'importance de l'IA g√©n√©rative responsable, examinons 4 √©tapes que nous pouvons suivre pour construire nos solutions d'IA de mani√®re responsable :

![Cycle d'att√©nuation](../../../translated_images/mitigate-cycle.b1882a83eedf881a929915d642ac7f6d07abb42de410724a730cca071c7c46ea.fr.png)

### Mesurer les dommages potentiels

En testant les logiciels, nous testons les actions attendues d'un utilisateur sur une application. De m√™me, tester un ensemble diversifi√© de sollicitations que les utilisateurs sont le plus susceptibles d'utiliser est un bon moyen de mesurer les dommages potentiels.

√âtant donn√© que notre startup construit un produit √©ducatif, il serait bon de pr√©parer une liste de sollicitations li√©es √† l'√©ducation. Cela pourrait √™tre pour couvrir un certain sujet, des faits historiques et des sollicitations sur la vie √©tudiante.

### Att√©nuer les dommages potentiels

Il est maintenant temps de trouver des moyens de pr√©venir ou de limiter les dommages potentiels caus√©s par le mod√®le et ses r√©ponses. Nous pouvons examiner cela sous 4 couches diff√©rentes :

![Couches d'att√©nuation](../../../translated_images/mitigation-layers.5e2c77a3d9f8a897b45f08e5c2c5d2c7a71f9e833e34249230cf9c0d90f669d4.fr.png)

- **Mod√®le**. Choisir le bon mod√®le pour le bon cas d'utilisation. Les mod√®les plus grands et plus complexes comme GPT-4 peuvent causer plus de risques de contenu nuisible lorsqu'ils sont appliqu√©s √† des cas d'utilisation plus petits et plus sp√©cifiques. L'utilisation de vos donn√©es de formation pour un affinage fin r√©duit √©galement le risque de contenu nuisible.

- **Syst√®me de s√©curit√©**. Un syst√®me de s√©curit√© est un ensemble d'outils et de configurations sur la plateforme servant le mod√®le qui aident √† att√©nuer les dommages. Un exemple de cela est le syst√®me de filtrage de contenu sur le service Azure OpenAI. Les syst√®mes doivent √©galement d√©tecter les attaques de jailbreak et les activit√©s ind√©sirables telles que les demandes de bots.

- **M√©ta-sollicitation**. Les m√©ta-sollicitations et la mise √† la terre sont des moyens de diriger ou de limiter le mod√®le en fonction de certains comportements et informations. Cela pourrait √™tre l'utilisation d'entr√©es syst√®me pour d√©finir certaines limites du mod√®le. De plus, fournir des sorties qui sont plus pertinentes pour la port√©e ou le domaine du syst√®me.

 Cela peut √©galement √™tre l'utilisation de techniques telles que la g√©n√©ration augment√©e de r√©cup√©ration (RAG) pour que le mod√®le ne tire des informations que d'une s√©lection de sources de confiance. Il y a une le√ßon plus tard dans ce cours pour [la construction d'applications de recherche](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Exp√©rience utilisateur**. La derni√®re couche est l√† o√π l'utilisateur interagit directement avec le mod√®le via l'interface de notre application d'une mani√®re ou d'une autre. De cette fa√ßon, nous pouvons concevoir l'interface utilisateur pour limiter l'utilisateur sur les types d'entr√©es qu'il peut envoyer au mod√®le ainsi que sur le texte ou les images affich√©es √† l'utilisateur. Lors du d√©ploiement de l'application d'IA, nous devons √©galement √™tre transparents sur ce que notre application d'IA g√©n√©rative peut et ne peut pas faire.

Nous avons une le√ßon enti√®re consacr√©e √† la [conception UX pour les applications d'IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **√âvaluer le mod√®le**. Travailler avec des LLM peut √™tre difficile car nous n'avons pas toujours le contr√¥le sur les donn√©es sur lesquelles le mod√®le a √©t√© form√©. Quoi qu'il en soit, nous devons toujours √©valuer la performance et les sorties du mod√®le. Il est toujours important de mesurer l'exactitude, la similarit√©, la mise √† la terre et la pertinence de la sortie du mod√®le. Cela aide √† fournir de la transparence et de la confiance aux parties prenantes et aux utilisateurs.

### Utiliser une solution d'IA g√©n√©rative responsable

La construction d'une pratique op√©rationnelle autour de vos applications d'IA est la derni√®re √©tape. Cela comprend le partenariat avec d'autres parties de notre startup comme le d√©partement juridique et la s√©curit√© pour nous assurer que nous sommes conformes √† toutes les politiques r√©glementaires. Avant le lancement, nous voulons √©galement √©laborer des plans autour de la livraison, de la gestion des incidents et du retour en arri√®re pour √©viter tout pr√©judice √† nos utilisateurs en croissance.

## Outils

Bien que le d√©veloppement de solutions d'IA responsable puisse sembler √™tre beaucoup de travail, c'est un travail qui en vaut la peine. √Ä mesure que le domaine de l'IA g√©n√©rative se d√©veloppe, de plus en plus d'outils pour aider les d√©veloppeurs √† int√©grer efficacement la responsabilit√© dans leurs flux de travail vont m√ªrir. Par exemple, le [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst ) peut aider √† d√©tecter le contenu nuisible et les images via une demande d'API.

## V√©rification des connaissances

Quelles sont certaines choses dont vous devez tenir compte pour assurer une utilisation responsable de l'IA ?

1. Que la r√©ponse est correcte.
2. L'utilisation nuisible, que l'IA n'est pas utilis√©e √† des fins criminelles.
3. Assurer que l'IA est exempte de biais et de discrimination.

R : Les options 2 et 3 sont correctes. L'IA responsable vous aide √† consid√©rer comment att√©nuer les effets nuisibles et les biais, et plus encore.

## üöÄ D√©fi

Lisez [Azure AI Content Saftey](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) et voyez ce que vous pouvez adopter pour votre utilisation.

## Excellent travail, continuez votre apprentissage

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† am√©liorer vos connaissances en IA g√©n√©rative !

Rendez-vous √† la le√ßon 4 o√π nous examinerons les [Fondamentaux de l'ing√©nierie de sollicitations](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!


Avertissement: La traduction a √©t√© traduite de son original par un mod√®le d'IA et peut ne pas √™tre parfaite. Veuillez v√©rifier la sortie et apporter toutes les corrections n√©cessaires.