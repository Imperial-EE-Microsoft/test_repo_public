# Exploration et comparaison de diff√©rents LLM

[![Exploration et comparaison de diff√©rents LLM](./images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://learn.microsoft.com/_themes/docs.theme/master/en-us/_themes/global/video-embed.html?id=39aa0f98-826a-4f71-a24d-e888a8e80246?WT.mc_id=academic-105485-koreyst)

> *Cliquez sur l'image ci-dessus pour voir la vid√©o de cette le√ßon*

Dans la le√ßon pr√©c√©dente, nous avons vu comment l'IA g√©n√©rative change le paysage technologique, comment les grands mod√®les de langage (LLMs) fonctionnent et comment une entreprise - comme notre start-up - peut les appliquer √† ses cas d'utilisation et se d√©velopper ! Dans ce chapitre, nous cherchons √† comparer et √† contraster diff√©rents types de grands mod√®les de langage (LLMs) pour comprendre leurs avantages et inconv√©nients.

La prochaine √©tape dans le parcours de notre start-up consiste √† explorer le paysage actuel des LLMs et √† comprendre ceux qui conviennent le mieux √† notre cas d'utilisation.

## Introduction

Cette le√ßon couvrira :

- Diff√©rents types de LLMs dans le paysage actuel.
- Tester, it√©rer et comparer diff√©rents mod√®les pour votre cas d'utilisation dans Azure.
- Comment d√©ployer un LLM.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous serez en mesure de :

- S√©lectionner le bon mod√®le pour votre cas d'utilisation.
- Comprendre comment tester, it√©rer et am√©liorer les performances de votre mod√®le.
- Savoir comment les entreprises d√©ploient des mod√®les.

## Comprendre les diff√©rents types de LLMs

Les LLMs peuvent avoir plusieurs cat√©gorisations bas√©es sur leur architecture, leurs donn√©es d'entra√Ænement et leur cas d'utilisation. Comprendre ces diff√©rences aidera notre start-up √† s√©lectionner le bon mod√®le pour le sc√©nario et √† comprendre comment tester, it√©rer et am√©liorer les performances.

Il existe de nombreux types diff√©rents de mod√®les LLM, votre choix de mod√®le d√©pend de ce que vous voulez les utiliser pour, vos donn√©es, combien vous √™tes pr√™t √† payer et plus encore.

En fonction de si vous voulez utiliser les mod√®les pour la g√©n√©ration de texte, d'audio, de vid√©o, d'image, etc., vous pouvez opter pour un type de mod√®le diff√©rent.

- **Reconnaissance audio et vocale**. Pour cette fin, les mod√®les Whisper sont un excellent choix car ils sont g√©n√©ralistes et destin√©s √† la reconnaissance vocale. Il est entra√Æn√© sur des audios divers et peut effectuer une reconnaissance vocale multilingue. En savoir plus sur les [mod√®les Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **G√©n√©ration d'image**. Pour la g√©n√©ration d'images, DALL-E et Midjourney sont deux choix tr√®s connus. DALL-E est propos√© par Azure OpenAI. [En savoir plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) et √©galement dans le chapitre 9 de ce programme.

- **G√©n√©ration de texte**. La plupart des mod√®les sont form√©s sur la g√©n√©ration de texte et vous avez une grande vari√©t√© de choix, de GPT-3.5 √† GPT-4. Ils ont des co√ªts diff√©rents, GPT-4 √©tant le plus cher. Il vaut la peine de consulter le [terrain de jeu Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour √©valuer quels mod√®les conviennent le mieux √† vos besoins en termes de capacit√© et de co√ªt.

- **Multi-modalit√©**. Si vous cherchez √† g√©rer plusieurs types de donn√©es en entr√©e et en sortie, vous voudrez peut-√™tre vous pencher sur des mod√®les comme [gpt-4 turbo avec vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - les derni√®res versions des mod√®les OpenAI - qui sont capables de combiner le traitement du langage naturel √† la compr√©hension visuelle, permettant des interactions via des interfaces multi-modales.

S√©lectionner un mod√®le signifie que vous obtenez certaines capacit√©s de base, qui pourraient ne pas √™tre suffisantes. Souvent, vous avez des donn√©es sp√©cifiques √† l'entreprise que vous devez somehow need to tell the LLM about. Il existe quelques choix diff√©rents sur la fa√ßon d'aborder cela, plus sur cela dans les sections √† venir.

### Mod√®les de base versus LLMs

Le terme de mod√®le de base a √©t√© [invent√© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et d√©fini comme un mod√®le d'IA qui suit certains crit√®res, tels que :

- **Ils sont entra√Æn√©s √† l'aide d'un apprentissage non supervis√© ou auto-supervis√©**, ce qui signifie qu'ils sont entra√Æn√©s sur des donn√©es multimodales non √©tiquet√©es et qu'ils ne n√©cessitent pas d'annotation humaine ou d'√©tiquetage de donn√©es pour leur processus d'entra√Ænement.
- **Ils sont des mod√®les tr√®s grands**, bas√©s sur des r√©seaux de neurones tr√®s profonds entra√Æn√©s sur des milliards de param√®tres.
- **Ils sont normalement destin√©s √† servir de "base" pour d'autres mod√®les**, ce qui signifie qu'ils peuvent √™tre utilis√©s comme point de d√©part pour la construction d'autres mod√®les, qui peuvent √™tre r√©alis√©s par ajustement fin.

![Mod√®les de base versus LLMs](./images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

Source de l'image : [Guide essentiel des mod√®les de base et des grands mod√®les de langage | par Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier davantage cette distinction, prenons l'exemple de ChatGPT. Pour construire la premi√®re version de ChatGPT, un mod√®le appel√© GPT-3.5 a servi de mod√®le de base. Cela signifie qu'OpenAI a utilis√© des donn√©es sp√©cifiques au chat pour cr√©er une version r√©gl√©e de GPT-3.5 qui √©tait sp√©cialis√©e dans la r√©alisation de performances √©lev√©es dans des sc√©narios conversationnels, tels que les chatbots.

![Mod√®le de base](./images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

Source de l'image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Mod√®les open source versus propri√©taires

Une autre fa√ßon de cat√©goriser les LLMs est de savoir s'ils sont open source ou propri√©taires.

Les mod√®les open source sont des mod√®les qui sont mis √† disposition du public et peuvent √™tre utilis√©s par tout le monde. Ils sont souvent mis √† disposition par l'entreprise qui les a cr√©√©s ou par la communaut√© de recherche. Ces mod√®les peuvent √™tre inspect√©s, modifi√©s et personnalis√©s pour les diff√©rents cas d'utilisation dans les LLMs. Cependant, ils ne sont pas toujours optimis√©s pour une utilisation en production et peuvent ne pas √™tre aussi performants que les mod√®les propri√©taires. De plus, le financement des mod√®les open source peut √™tre limit√©, et ils peuvent ne pas √™tre maintenus √† long terme ou ne pas √™tre mis √† jour avec les derni√®res recherches. Des exemples de mod√®les open source populaires incluent [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-koreyst) et [LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-koreyst).

Les mod√®les propri√©taires sont des mod√®les qui appartiennent √† une entreprise et ne sont pas mis √† disposition du public. Ces mod√®les sont souvent optimis√©s pour une utilisation en production. Cependant, ils ne sont pas autoris√©s √† √™tre inspect√©s, modifi√©s ou personnalis√©s pour diff√©rents cas d'utilisation. De plus, ils ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s. De plus, les utilisateurs n'ont pas le contr√¥le sur les donn√©es utilis√©es pour entra√Æner le mod√®le, ce qui signifie qu'ils doivent confier au propri√©taire du mod√®le la responsabilit√© de garantir la confidentialit√© des donn√©es et une utilisation responsable de l'IA. Des exemples de mod√®les propri√©taires populaires incluent [les mod√®les OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### G√©n√©ration d'embedding versus g√©n√©ration d'images versus g√©n√©ration de texte et de code

Les LLMs peuvent √©galement √™tre cat√©goris√©s par la sortie qu'ils g√©n√®rent.

Les embeddings sont un ensemble de mod√®les qui peuvent convertir du texte en une forme num√©rique, appel√©e embedding, qui est une repr√©sentation num√©rique du texte d'entr√©e. Les embeddings facilitent la compr√©hension des relations entre les mots ou les phrases par les machines et peuvent √™tre consomm√©s en tant qu'entr√©es par d'autres mod√®les, tels que les mod√®les de classification ou de clustering qui ont de meilleures performances sur les donn√©es num√©riques. Les mod√®les d'embedding sont souvent utilis√©s pour l'apprentissage par transfert, o√π un mod√®le est construit pour une t√¢che de substitution pour laquelle il y a une abondance de donn√©es, puis les poids du mod√®le (embeddings) sont r√©utilis√©s pour d'autres t√¢ches aval. Un exemple de cette cat√©gorie est [les embeddings OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](./images/Embedding.png?WT.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration d'images sont des mod√®les qui g√©n√®rent des images. Ces mod√®les sont souvent utilis√©s pour l'√©dition d'images, la synth√®se d'images et la traduction d'images. Les mod√®les de g√©n√©ration d'images sont souvent entra√Æn√©s sur de grands ensembles de donn√©es d'images, tels que [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouvelles images ou pour √©diter des images existantes avec des techniques d'inpainting, de super-r√©solution et de colorisation. Les exemples incluent [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![G√©n√©ration d'image](./images/Image.png?WT.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration de texte et de code sont des mod√®les qui g√©n√®rent du texte ou du code. Ces mod√®les sont souvent utilis√©s pour la synth√®se de texte, la traduction et la r√©ponse aux questions. Les mod√®les de g√©n√©ration de texte sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de texte, tels que [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau texte ou pour r√©pondre √† des questions. Les mod√®les de g√©n√©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de code, tels que GitHub, et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau code ou pour corriger des bogues dans du code existant.

![G√©n√©ration de texte et de code](./images/Text.png?WT.mc_id=academic-105485-koreyst)

### Encodeur-d√©codeur versus d√©codeur uniquement

Pour parler des diff√©rents types d'architectures de LLMs, utilisons une analogie.

Imaginez que votre responsable vous a confi√© la t√¢che d'√©crire un quiz pour les √©tudiants. Vous avez deux coll√®gues ; l'un supervise la cr√©ation du contenu et l'autre supervise la relecture.

Le cr√©ateur de contenu est comme un mod√®le de d√©codeur uniquement, il peut regarder le sujet et voir ce que vous avez d√©j√† √©crit, puis il peut √©crire un cours en fonction de cela. Il est tr√®s dou√© pour √©crire du contenu engageant et informatif, mais il n'est pas tr√®s dou√© pour comprendre le sujet et les objectifs d'apprentissage. Certains exemples de mod√®les de d√©codeur sont les mod√®les de la famille GPT, tels que GPT-3.

Le relecteur est comme un mod√®le d'encodeur uniquement, il regarde le cours √©crit et les r√©ponses, remarque la relation entre eux et comprend le contexte, mais il n'est pas bon pour g√©n√©rer du contenu. Un exemple de mod√®le d'encodeur uniquement serait BERT.

Imaginez maintenant que nous puissions avoir quelqu'un qui pourrait cr√©er et revoir le quiz, c'est un mod√®le encodeur-d√©codeur. Quelques exemples seraient BART et T5.

### Service versus mod√®le

Maintenant, parlons de la diff√©rence entre un service et un mod√®le. Un service est un produit propos√© par un fournisseur de services cloud, et est souvent une combinaison de mod√®les, de donn√©es et d'autres composants. Un mod√®le est le composant principal d'un service, et est souvent un mod√®le de base, tel qu'un LLM.

Les services sont souvent optimis√©s pour une utilisation en production et sont souvent plus faciles √† utiliser que les mod√®les, via une interface utilisateur graphique. Cependant, les services ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s, en √©change de l'utilisation de l'√©quipement et des ressources du propri√©taire de service, optimisant les d√©penses et l'√©volutivit√©. Un exemple de service est [le service Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui offre un plan tarifaire de type pay-as-you-go, ce qui signifie que les utilisateurs sont factur√©s proportionnellement √† leur utilisation du service. De plus, Azure OpenAI service offre une s√©curit√© de qualit√© entreprise et un cadre d'IA responsable en plus des capacit√©s des mod√®les.

Les mod√®les ne sont que le r√©seau de neurones, avec les param√®tres, les poids, et autres. Les entreprises peuvent les ex√©cuter localement, mais cela n√©cessite l'achat d'√©quipement, la construction d'une structure pour l'√©volutivit√© et l'achat d'une licence ou l'utilisation d'un mod√®le open source. Un mod√®le comme LLaMA est disponible pour √™tre utilis√©, n√©cessitant une puissance de calcul pour ex√©cuter le mod√®le.

## Comment tester et it√©rer avec diff√©rents mod√®les pour comprendre les performances sur Azure

Une fois que notre √©quipe a explor√© le paysage actuel des LLMs et identifi√© de bons candidats pour leurs sc√©narios, l'√©tape suivante consiste √† les tester sur leurs donn√©es et leur charge de travail. Il s'agit d'un processus it√©ratif, r√©alis√© par des exp√©riences et des mesures. La plupart des mod√®les que nous avons mentionn√©s dans les paragraphes pr√©c√©dents (mod√®les OpenAI, mod√®les open source comme Llama2 et transformateurs Hugging Face) sont disponibles dans le [Catalogue de mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) dans [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plateforme cloud con√ßue pour les d√©veloppeurs pour construire des applications d'IA g√©n√©rative et g√©rer tout le cycle de d√©veloppement - de l'exp√©rimentation √† l'√©valuation - en combinant tous les services d'IA Azure en un seul hub avec une interface graphique pratique. Le catalogue de mod√®les dans Azure AI Studio permet √† l'utilisateur de :

- Trouver le mod√®le de base qui l'int√©resse dans le catalogue - propri√©taire ou open source, en filtrant par t√¢che, licence ou nom. Pour am√©liorer la recherche, les mod√®les sont organis√©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et plus encore.

![Catalogue de mod√®les](./images/AzureAIStudioModelCatalog.png?WT.mc_id=academic-105485-koreyst)

- Examiner la fiche du mod√®le, y compris une description d√©taill√©e de l'utilisation pr√©vue et des donn√©es d'entra√Ænement, des exemples de code et des r√©sultats d'√©valuation sur la biblioth√®que d'√©valuations internes.

![Fiche du mod√®le](./images/ModelCard.png?WT.mc_id
Pour r√©pondre aux attentes de l'utilisateur, la r√©ponse sera adapt√©e. Dans ce cas, on parle d'apprentissage "one-shot" si la demande ne comprend qu'un seul exemple et d'apprentissage "few shot" s'il comprend plusieurs exemples. L'ing√©nierie de prompt avec contexte est l'approche la plus rentable pour commencer. ### La g√©n√©ration augment√©e par r√©cup√©ration (RAG) Les LLMs augment√©s par r√©cup√©ration ont pour limite d'utiliser uniquement les donn√©es qui ont √©t√© utilis√©es pendant leur formation pour g√©n√©rer une r√©ponse. Cela signifie qu'ils ne connaissent rien des faits qui se sont produits apr√®s leur processus de formation et qu'ils ne peuvent pas acc√©der aux informations non publiques (comme les donn√©es d'entreprise). Cela peut √™tre surmont√© gr√¢ce √† RAG, une technique qui augmente le prompt avec des donn√©es externes sous forme de morceaux de documents, en consid√©rant les limites de longueur du prompt. Cela est soutenu par des outils de base de donn√©es vectoriels (comme [Azure Vector Search] (https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui r√©cup√®rent les morceaux utiles de sources de donn√©es pr√©d√©finies vari√©es et les ajoutent au contexte du prompt. Cette technique est tr√®s utile lorsqu'une entreprise n'a pas suffisamment de donn√©es, de temps ou de ressources pour affiner un LLM, mais souhaite n√©anmoins am√©liorer les performances sur une charge de travail sp√©cifique et r√©duire les risques de fabrications, c'est-√†-dire la mystification de la r√©alit√© ou le contenu nuisible. ### Mod√®le affin√© L'affinage est un processus qui exploite l'apprentissage par transfert pour "adapter" le mod√®le √† une t√¢che en aval ou pour r√©soudre un probl√®me sp√©cifique. Contrairement √† l'apprentissage few-shot et √† RAG, cela r√©sulte en la g√©n√©ration d'un nouveau mod√®le, avec des poids et des biais mis √† jour. Il n√©cessite un ensemble d'exemples d'entra√Ænement consistant en une seule entr√©e (le prompt) et sa sortie associ√©e (la compl√©tion). Ce serait l'approche pr√©f√©r√©e si: - **En utilisant des mod√®les affin√©s**. Une entreprise souhaiterait utiliser des mod√®les d'incorporation moins performants (comme les mod√®les d'incorporation) plut√¥t que des mod√®les haute performance, ce qui entra√Ænerait une solution plus rentable et plus rapide. - **Consid√©rant la latence**. La latence est importante pour un cas d'utilisation sp√©cifique, il n'est donc pas possible d'utiliser des prompts tr√®s longs ou le nombre d'exemples √† apprendre √† partir du mod√®le ne correspond pas √† la limite de longueur du prompt. - **Rester √† jour**. Une entreprise dispose de beaucoup de donn√©es de haute qualit√© et d'√©tiquettes de v√©rit√© terrain et des ressources n√©cessaires pour maintenir ces donn√©es √† jour au fil du temps. ### Mod√®le entra√Æn√© Former un LLM √† partir de z√©ro est sans aucun doute l'approche la plus difficile et la plus complexe √† adopter, n√©cessitant des quantit√©s massives de donn√©es, des ressources qualifi√©es et une puissance de calcul appropri√©e. Cette option ne devrait √™tre envisag√©e que dans un sc√©nario o√π une entreprise a un cas d'utilisation sp√©cifique au domaine et une grande quantit√© de donn√©es centr√©es sur le domaine. ## V√©rification des connaissances Quelle pourrait √™tre une bonne approche pour am√©liorer les r√©sultats de compl√©tion de LLM? 1. Ing√©nierie de prompt avec contexte 1. RAG 1. Mod√®le affin√© R:3, si vous avez le temps et les ressources et des donn√©es de haute qualit√©, l'affinage est la meilleure option pour rester √† jour. Cependant, si vous cherchez √† am√©liorer les choses et que vous manquez de temps, il vaut la peine de consid√©rer RAG en premier. ## üöÄ D√©fi En savoir plus sur la fa√ßon dont vous pouvez [utiliser RAG] (https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise. ## Excellent travail, continuez votre apprentissage Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage de l'IA g√©n√©rative] (https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† am√©liorer vos connaissances en IA g√©n√©rative! Rendez-vous √† la le√ßon 3 o√π nous verrons comment [construire avec l'IA g√©n√©rative de mani√®re responsable] (../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!


Avertissement : La traduction a √©t√© traduite √† partir de son original par un mod√®le d'IA et peut ne pas √™tre parfaite. Veuillez v√©rifier la sortie et apporter toutes les corrections n√©cessaires.