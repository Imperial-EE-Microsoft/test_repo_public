# Exploration et comparaison de diff√©rents LLM

[![Exploration et comparaison de diff√©rents LLM](./images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://learn.microsoft.com/_themes/docs.theme/master/en-us/_themes/global/video-embed.html?id=39aa0f98-826a-4f71-a24d-e888a8e80246?WT.mc_id=academic-105485-koreyst)

> *Cliquez sur l'image ci-dessus pour visionner la vid√©o de cette le√ßon.*

Avec la le√ßon pr√©c√©dente, nous avons vu comment l'IA g√©n√©rative change le paysage technologique, comment les grands mod√®les de langage (LLMs) fonctionnent et comment une entreprise - comme notre start-up - peut les appliquer √† ses cas d'utilisation et se d√©velopper ! Dans ce chapitre, nous cherchons √† comparer et √† contraster diff√©rents types de grands mod√®les de langage (LLMs) pour comprendre leurs avantages et inconv√©nients.

La prochaine √©tape du parcours de notre start-up est d'explorer le paysage actuel des LLMs et de comprendre lesquels conviennent √† notre cas d'utilisation.

## Introduction

Cette le√ßon couvrira :

- Diff√©rents types de LLMs dans le paysage actuel.
- Tester, it√©rer et comparer diff√©rents mod√®les pour votre cas d'utilisation dans Azure.
- Comment d√©ployer un LLM.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous serez capable de :

- S√©lectionner le bon mod√®le pour votre cas d'utilisation.
- Comprendre comment tester, it√©rer et am√©liorer les performances de votre mod√®le.
- Savoir comment les entreprises d√©ploient des mod√®les.

## Comprendre les diff√©rents types de LLMs

Les LLMs peuvent avoir plusieurs cat√©gories en fonction de leur architecture, de leurs donn√©es d'entra√Ænement et de leur cas d'utilisation. Comprendre ces diff√©rences aidera notre start-up √† s√©lectionner le bon mod√®le pour le sc√©nario et √† comprendre comment tester, it√©rer et am√©liorer les performances.

Il existe de nombreux types diff√©rents de mod√®les LLM, votre choix de mod√®le d√©pend de ce que vous souhaitez les utiliser, de vos donn√©es, de ce que vous √™tes pr√™t √† payer et plus encore.

Selon que vous visez √† utiliser les mod√®les pour la g√©n√©ration de texte, d'audio, de vid√©o, d'image, etc., vous pouvez opter pour un type de mod√®le diff√©rent.

- **Reconnaissance audio et vocale**. Pour cette fin, les mod√®les de type Whisper sont un excellent choix car ils sont polyvalents et destin√©s √† la reconnaissance vocale. Il est entra√Æn√© sur des donn√©es audio diverses et peut effectuer une reconnaissance vocale multilingue. En savoir plus sur [les mod√®les Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **G√©n√©ration d'images**. Pour la g√©n√©ration d'images, DALL-E et Midjourney sont deux choix tr√®s connus. DALL-E est propos√© par Azure OpenAI. [En savoir plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) et √©galement dans le chapitre 9 de ce programme.

- **G√©n√©ration de texte**. La plupart des mod√®les sont entra√Æn√©s sur la g√©n√©ration de texte et vous avez une grande vari√©t√© de choix, de GPT-3.5 √† GPT-4. Ils ont des co√ªts diff√©rents, GPT-4 √©tant le plus cher. Il vaut la peine de regarder le [terrain de jeu Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour √©valuer quels mod√®les conviennent le mieux √† vos besoins en termes de capacit√© et de co√ªt.

- **Multimodalit√©**. Si vous cherchez √† g√©rer plusieurs types de donn√©es en entr√©e et en sortie, vous voudrez peut-√™tre examiner des mod√®les comme [gpt-4 turbo with vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - les derni√®res versions des mod√®les OpenAI - qui sont capables de combiner le traitement du langage naturel √† la compr√©hension visuelle, permettant des interactions via des interfaces multimodales.

S√©lectionner un mod√®le signifie que vous obtenez certaines capacit√©s de base, qui pourraient ne pas √™tre suffisantes. Souvent, vous avez des donn√©es sp√©cifiques √† l'entreprise que vous devez somehow faire savoir au LLM. Il existe plusieurs choix diff√©rents sur la fa√ßon d'aborder cela, plus sur cela dans les sections √† venir.

### Mod√®les de base versus LLMs

Le terme mod√®le de base a √©t√© [cr√©√© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et d√©fini comme un mod√®le d'IA qui suit certains crit√®res, tels que :

- **Ils sont entra√Æn√©s √† l'aide d'un apprentissage non supervis√© ou d'un apprentissage auto-supervis√©**, ce qui signifie qu'ils sont entra√Æn√©s sur des donn√©es multimodales non √©tiquet√©es et qu'ils ne n√©cessitent pas d'annotation ou d'√©tiquetage humain des donn√©es pour leur processus d'entra√Ænement.
- **Ce sont des mod√®les tr√®s volumineux**, bas√©s sur des r√©seaux neuronaux tr√®s profonds entra√Æn√©s sur des milliards de param√®tres.
- **Ils sont normalement destin√©s √† servir de ¬´ base ¬ª pour d'autres mod√®les**, ce qui signifie qu'ils peuvent √™tre utilis√©s comme point de d√©part pour la construction d'autres mod√®les, qui peuvent √™tre faits par fine-tuning.

![Mod√®les de base versus LLMs](./images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

Source de l'image : [Guide essentiel des mod√®les de base et des grands mod√®les de langage | par Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier davantage cette distinction, prenons ChatGPT comme exemple. Pour construire la premi√®re version de ChatGPT, un mod√®le appel√© GPT-3.5 a servi de mod√®le de base. Cela signifie qu'OpenAI a utilis√© des donn√©es sp√©cifiques au chat pour cr√©er une version ajust√©e de GPT-3.5 qui √©tait sp√©cialis√©e dans la r√©alisation de performances optimales dans des sc√©narios de conversation, tels que les chatbots.

![Mod√®le de base](./images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

Source de l'image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Mod√®les open source versus propri√©taires

Une autre fa√ßon de cat√©goriser les LLMs est de savoir s'ils sont open source ou propri√©taires.

Les mod√®les open source sont des mod√®les mis √† la disposition du public et peuvent √™tre utilis√©s par n'importe qui. Ils sont souvent mis √† disposition par la soci√©t√© qui les a cr√©√©s ou par la communaut√© de recherche. Ces mod√®les sont autoris√©s √† √™tre inspect√©s, modifi√©s et personnalis√©s pour les diff√©rents cas d'utilisation dans les LLMs. Cependant, ils ne sont pas toujours optimis√©s pour une utilisation en production et peuvent ne pas √™tre aussi performants que les mod√®les propri√©taires. De plus, le financement des mod√®les open source peut √™tre limit√© et ils peuvent ne pas √™tre maintenus √† long terme ou ne pas √™tre mis √† jour avec les derni√®res recherches. Des exemples de mod√®les open source populaires comprennent [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-koreyst) et [LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-koreyst).

Les mod√®les propri√©taires sont des mod√®les qui appartiennent √† une entreprise et qui ne sont pas mis √† disposition du public. Ces mod√®les sont souvent optimis√©s pour une utilisation en production. Cependant, ils ne sont pas autoris√©s √† √™tre inspect√©s, modifi√©s ou personnalis√©s pour diff√©rents cas d'utilisation. De plus, ils ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s. De plus, les utilisateurs n'ont pas le contr√¥le sur les donn√©es utilis√©es pour entra√Æner le mod√®le, ce qui signifie qu'ils doivent confier au propri√©taire du mod√®le l'assurance du respect de la confidentialit√© des donn√©es et de l'utilisation responsable de l'IA. Des exemples de mod√®les propri√©taires populaires comprennent [les mod√®les OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus g√©n√©ration d'images versus g√©n√©ration de texte et de code

Les LLMs peuvent √©galement √™tre cat√©goris√©s par la sortie qu'ils g√©n√®rent.

Les embeddings sont un ensemble de mod√®les qui peuvent convertir du texte en une forme num√©rique, appel√©e embedding, qui est une repr√©sentation num√©rique du texte d'entr√©e. Les embeddings facilitent la compr√©hension par les machines des relations entre les mots ou les phrases et peuvent √™tre consomm√©s en tant qu'entr√©es par d'autres mod√®les, tels que les mod√®les de classification ou de clustering qui ont de meilleures performances sur les donn√©es num√©riques. Les mod√®les d'embedding sont souvent utilis√©s pour le transfert d'apprentissage, o√π un mod√®le est construit pour une t√¢che de substitution pour laquelle il y a une abondance de donn√©es, puis les poids du mod√®le (embeddings) sont r√©utilis√©s pour d'autres t√¢ches en aval. Un exemple de cette cat√©gorie est [les embeddings OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](./images/Embedding.png?WT.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration d'images sont des mod√®les qui g√©n√®rent des images. Ces mod√®les sont souvent utilis√©s pour l'√©dition d'images, la synth√®se d'images et la traduction d'images. Les mod√®les de g√©n√©ration d'images sont souvent entra√Æn√©s sur de grands ensembles de donn√©es d'images, tels que [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouvelles images ou pour √©diter des images existantes avec des techniques d'inpainting, de super-r√©solution et de colorisation. Les exemples incluent [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [les mod√®les de diffusion stable](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![G√©n√©ration d'images](./images/Image.png?WT.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration de texte et de code sont des mod√®les qui g√©n√®rent du texte ou du code. Ces mod√®les sont souvent utilis√©s pour la synth√®se de texte, la traduction et la r√©ponse aux questions. Les mod√®les de g√©n√©ration de texte sont souvent entra√Æn√©s sur de grands ensembles de donn√©es textuelles, tels que [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau texte ou pour r√©pondre √† des questions. Les mod√®les de g√©n√©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de code, tels que GitHub, et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau code ou pour corriger des bugs dans du code existant.

 ![G√©n√©ration de texte et de code](./images/Text.png?WT.mc_id=academic-105485-koreyst)

### Encodeur-d√©codeur versus d√©codeur uniquement

Pour parler des diff√©rents types d'architectures de LLMs, utilisons une analogie.

Imaginez que votre responsable vous a confi√© la t√¢che d'√©crire un quiz pour les √©tudiants. Vous avez deux coll√®gues ; l'un supervise la cr√©ation du contenu et l'autre supervise la r√©vision.

Le cr√©ateur de contenu est comme un mod√®le de d√©codeur unique, il peut regarder le sujet et voir ce que vous avez d√©j√† √©crit, puis il peut √©crire un cours en fonction de cela. Il est tr√®s bon pour √©crire du contenu engageant et informatif, mais il n'est pas tr√®s bon pour comprendre le sujet et les objectifs d'apprentissage. Certains exemples de mod√®les de d√©codeur sont les mod√®les de la famille GPT, tels que GPT-3.

Le r√©viseur est comme un mod√®le d'encodeur uniquement, il regarde le cours √©crit et les r√©ponses, remarque la relation entre eux et comprend le contexte, mais il n'est pas bon pour g√©n√©rer du contenu. Un exemple de mod√®le d'encodeur unique serait BERT.

Imaginez que nous pouvons √©galement avoir quelqu'un qui pourrait cr√©er et r√©viser le quiz, c'est un mod√®le encodeur-d√©codeur. Certains exemples seraient BART et T5.

### Service versus mod√®le

Maintenant, parlons de la diff√©rence entre un service et un mod√®le. Un service est un produit propos√© par un fournisseur de services cloud et est souvent une combinaison de mod√®les, de donn√©es et d'autres composants. Un mod√®le est le composant principal d'un service et est souvent un mod√®le de base, tel qu'un LLM.

Les services sont souvent optimis√©s pour une utilisation en production et sont souvent plus faciles √† utiliser que les mod√®les, via une interface utilisateur graphique. Cependant, les services ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s, en √©change de l'utilisation de l'√©quipement et des ressources du propri√©taire du service, optimisant les d√©penses et l'√©volutivit√©. Un exemple de service est [le service Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui offre un plan tarifaire pay-as-you-go, ce qui signifie que les utilisateurs sont factur√©s proportionnellement √† leur utilisation du service. De plus, le service Azure OpenAI offre une s√©curit√© de niveau entreprise et un cadre d'IA responsable en plus des capacit√©s des mod√®les.

Les mod√®les ne sont que le r√©seau neuronal, avec les param√®tres, les poids et autres. Les entreprises peuvent les ex√©cuter localement, mais elles doivent acheter du mat√©riel, construire une structure pour l'√©volutivit√© et acheter une licence ou utiliser un mod√®le open source. Un mod√®le comme LLaMA est disponible √† √™tre utilis√©, n√©cessitant une puissance de calcul pour ex√©cuter le mod√®le.

## Comment tester et it√©rer avec diff√©rents mod√®les pour comprendre les performances sur Azure

Une fois que notre √©quipe a explor√© le paysage actuel des LLMs et identifi√© certains bons candidats pour leurs sc√©narios, la prochaine √©tape consiste √† les tester sur leurs donn√©es et leur charge de travail. Il s'agit d'un processus it√©ratif, effectu√© par des exp√©riences et des mesures.
La plupart des mod√®les que nous avons mentionn√©s dans les paragraphes pr√©c√©dents (mod√®les OpenAI, mod√®les open source comme Llama2 et Hugging Face transformers) sont disponibles dans le [Catalogue de mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) dans [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plate-forme cloud con√ßue pour les d√©veloppeurs pour construire des applications d'IA g√©n√©rative et g√©rer l'ensemble du cycle de d√©veloppement - de l'exp√©rimentation √† l'√©valuation - en combinant tous les services d'IA Azure dans un seul hub avec une interface graphique pratique. Le catalogue de mod√®les dans Azure AI Studio permet √† l'utilisateur de :

- Trouver le mod√®le de base qui l'int√©resse dans le catalogue - propri√©taire ou open source, en filtrant par t√¢che, licence ou nom. Pour am√©liorer la recherche, les mod√®les sont organis√©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et plus encore.

![Catalogue de mod√®les](./images/AzureAIStudioModelCatalog.png?WT.mc_id=academic-105485-koreyst)

- Examiner la carte du mod√®le, y compris une description d√©taill√©e de l'utilisation pr√©vue et des donn√©es d'entra√Ænement, des exemples de code et des r√©sultats d'√©valuation sur la biblioth√®que d'√©valuations internes.

![Carte du mod√®le](./images/ModelCard.png?WT.mc_id=
Pour r√©pondre aux attentes de l'utilisateur, la r√©ponse sera adapt√©e. Dans ce cas, on parle d'apprentissage ¬´ one-shot ¬ª si la demande ne comprend qu'un seul exemple et d'apprentissage ¬´ few shot ¬ª s'il comprend plusieurs exemples. L'ing√©nierie de la demande avec contexte est l'approche la plus rentable pour commencer. ### G√©n√©ration augment√©e de r√©cup√©ration (RAG) Les LLM (mod√®les de langage bas√©s sur les transformers) ont pour limite qu'ils ne peuvent utiliser que les donn√©es qui ont √©t√© utilis√©es pendant leur formation pour g√©n√©rer une r√©ponse. Cela signifie qu'ils ne connaissent rien des faits qui se sont produits apr√®s leur processus de formation et qu'ils ne peuvent pas acc√©der aux informations non publiques (comme les donn√©es de l'entreprise). Cela peut √™tre surmont√© gr√¢ce √† RAG, une technique qui augmente la demande avec des donn√©es externes sous forme de fragments de documents, en tenant compte des limites de longueur de la demande. Cela est soutenu par des outils de base de donn√©es vectorielles (comme [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui r√©cup√®rent les fragments utiles de sources de donn√©es pr√©d√©finies vari√©es et les ajoutent au contexte de la demande. Cette technique est tr√®s utile lorsqu'une entreprise n'a pas suffisamment de donn√©es, de temps ou de ressources pour affiner un LLM, mais souhaite toujours am√©liorer les performances sur une charge de travail sp√©cifique et r√©duire les risques de fabrications, c'est-√†-dire la mystification de la r√©alit√© ou le contenu nuisible. ### Mod√®le affin√© L'affinage est un processus qui exploite le transfert d'apprentissage pour ¬´ adapter ¬ª le mod√®le √† une t√¢che en aval ou pour r√©soudre un probl√®me sp√©cifique. Contrairement √† l'apprentissage few-shot et √† RAG, cela entra√Æne la g√©n√©ration d'un nouveau mod√®le, avec des poids et des biais mis √† jour. Il n√©cessite un ensemble d'exemples d'entra√Ænement compos√© d'une entr√©e unique (la demande) et de sa sortie associ√©e (la compl√©tion). Cela serait l'approche pr√©f√©r√©e si : - **Utilisation de mod√®les affin√©s**. Une entreprise souhaite utiliser des mod√®les d'incorporation moins performants (comme les mod√®les d'incorporation) plut√¥t que des mod√®les haute performance, ce qui donne une solution plus rentable et plus rapide. - **Consid√©ration de la latence**. La latence est importante pour un cas d'utilisation sp√©cifique, il n'est donc pas possible d'utiliser des demandes tr√®s longues ou le nombre d'exemples qui doivent √™tre appris √† partir du mod√®le ne correspond pas √† la limite de longueur de la demande. - **Rester √† jour**. Une entreprise dispose de nombreuses donn√©es de haute qualit√© et d'√©tiquettes de v√©rit√© terrain et des ressources n√©cessaires pour maintenir ces donn√©es √† jour au fil du temps. ### Mod√®le entra√Æn√© Former un LLM √† partir de z√©ro est sans aucun doute l'approche la plus difficile et la plus complexe √† adopter, n√©cessitant des quantit√©s massives de donn√©es, des ressources qualifi√©es et une puissance de calcul appropri√©e. Cette option ne doit √™tre envisag√©e que dans un sc√©nario o√π une entreprise dispose d'un cas d'utilisation sp√©cifique au domaine et d'une grande quantit√© de donn√©es centr√©es sur le domaine. ## V√©rification des connaissances Quelle pourrait √™tre une bonne approche pour am√©liorer les r√©sultats de compl√©tion LLM ? 1. Ing√©nierie de la demande avec contexte 2. RAG 3. Mod√®le affin√© R: 3, si vous avez le temps, les ressources et des donn√©es de haute qualit√©, l'affinage est la meilleure option pour rester √† jour. Cependant, si vous cherchez √† am√©liorer les choses et que vous manquez de temps, il vaut la peine de consid√©rer RAG en premier. ## üöÄ D√©fi Renseignez-vous davantage sur la fa√ßon dont vous pouvez [utiliser RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise. ## Excellent travail, continuez votre apprentissage Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage de l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† am√©liorer vos connaissances en mati√®re d'IA g√©n√©rative ! Passez √† la le√ßon 3 o√π nous verrons comment [construire avec l'IA g√©n√©rative de mani√®re responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) !


Avertissement: La traduction a √©t√© effectu√©e √† partir d'un mod√®le d'IA et peut ne pas √™tre parfaite. Veuillez examiner le r√©sultat et apporter les corrections n√©cessaires.